{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Cube Alchemy","text":"<p>Streamlined Multidimensional Analytics in Pure Python</p> <p>Transform disconnected tables into a coherent analytical framework that seamlessly works across your entire data. Cube Alchemy creates a unified schema from your pandas DataFrames, enabling powerful cross-dimensional analysis with minimal code.</p> <p>With Cube Alchemy, you gain a consistent semantic layer to interact with interconnected data. Query your entire data model as one cohesive entity instead of managing separate tables.</p> <p>Highlights</p> <ul> <li>Simple slicing and dicing \u2014 less manual joins and glue code</li> <li>Reusable metrics and stateful queries</li> <li>Works great in notebooks and apps (Streamlit/Panel)</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome. Please open an issue to discuss major changes first. PRs should include concise descriptions and, where applicable, tests or examples.</p>"},{"location":"examples/","title":"Examples","text":"<p>(Reserved for advanced, end-to-end examples. To be added.)</p>"},{"location":"installation/","title":"Installation","text":"<p>Requires Python 3.8+.</p> <pre><code>python -m venv venv\nvenv\\Scripts\\activate\npip install cube-alchemy\n</code></pre>"},{"location":"overview/","title":"Overview","text":"<p>Cube Alchemy turns pandas DataFrames into a unified analytic model and semantic layer\u2014so you can explore data declaratively, with less joins and glue code.</p>"},{"location":"overview/#capabilities","title":"Capabilities","text":"<ul> <li> <p>Connects DataFrames automatically via shared column names</p> </li> <li> <p>Handles composite keys and complex relationships transparently</p> </li> <li> <p>Define reusable metrics and queries</p> </li> <li> <p>Maintain stateful context to compare scenarios</p> </li> </ul>"},{"location":"overview/#why-it-matters","title":"Why It Matters","text":"<p>Ship insights faster and reduce maintenance.</p> <ul> <li> <p>Speed: Relationships are discovered automatically</p> </li> <li> <p>Simplicity: Pure Python queries replace unnecessary ad\u2011hoc joins</p> </li> <li> <p>Consistency: Standardized metrics and filters yield reliable results</p> </li> <li> <p>Maintainability: Centralized business logic in reusable components</p> </li> <li> <p>Integration: Works great with Streamlit and other app frameworks</p> </li> </ul>"},{"location":"overview/#semantic-layer","title":"Semantic Layer","text":"<p>Map raw tables to a consistent set of analysis concepts:</p> <ul> <li> <p>Dimensions: Entities in your domain (e.g., Customer, Region, Product; Device, Study, Site)</p> </li> <li> <p>Metrics: Key measures (e.g., Revenue, Conversion Rate; Throughput, Accuracy)</p> </li> <li> <p>Queries: Analyses (e.g., Performance by Group; Trends over Time)</p> </li> </ul>"},{"location":"streamlit/","title":"Streamlit Integration","text":"<p>(Reserved for a more advanced guide than the README. To be added.)</p>"},{"location":"api/filter_methods/","title":"Filter Methods","text":""},{"location":"api/filter_methods/#apply-filter","title":"Apply Filter","text":"<pre><code>filter(\n  criteria: Dict[str, List[Any]], \n  context_state_name: str = 'Default'\n) -&gt; bool\n</code></pre> <p>Apply filters to focus analysis on specific data slices.</p> <p>Parameters:</p> <ul> <li><code>criteria</code>: Dictionary mapping dimension names to lists of values to keep</li> <li><code>context_state_name</code>: Which context state to filter</li> </ul> <p>Returns:</p> <ul> <li>Boolean indicating success</li> </ul> <p>Example:</p> <pre><code># Filter to specific regions\ncube.filter({'region': ['North', 'South']})\n\n# Filter to specific products within those regions\ncube.filter({'product': ['Electronics', 'Home']})\n\n# Filter in a different context state\ncube.filter({'region': ['West']}, context_state_name='State1')\n</code></pre>"},{"location":"api/filter_methods/#remove-filter","title":"Remove Filter","text":"<pre><code>remove_filter(\n  dimensions: List[str],\n  context_state_name: str = 'Default'\n) -&gt; bool\n</code></pre> <p>Remove filters from specified dimensions.</p> <p>Parameters:</p> <ul> <li><code>dimensions</code>: List of dimension names to remove filters from</li> <li><code>context_state_name</code>: Which context state to modify</li> </ul> <p>Returns:</p> <ul> <li>Boolean indicating success</li> </ul> <p>Example:</p> <pre><code># Remove region filter\ncube.remove_filter(['region'])\n</code></pre>"},{"location":"api/filter_methods/#reset-filters","title":"Reset Filters","text":"<pre><code>reset_filters(\n  direction: str = 'backward',\n  context_state_name: str = 'Default'\n) -&gt; bool\n</code></pre> <p>Reset filters using undo/redo functionality or clear all filters.</p> <p>Parameters:</p> <ul> <li><code>direction</code>: 'backward' (undo), 'forward' (redo), or 'all' (clear all filters)</li> <li><code>context_state_name</code>: Which context state to modify</li> </ul> <p>Returns:</p> <ul> <li>Boolean indicating success</li> </ul> <p>Example:</p> <pre><code># Undo last filter operation\ncube.reset_filters('backward')\n\n# Redo previously undone filter operation\ncube.reset_filters('forward')\n\n# Clear all filters\ncube.reset_filters('all')\n</code></pre>"},{"location":"api/filter_methods/#get-filters","title":"Get Filters","text":"<pre><code>get_filters(\n  off_set: int = 0,\n  context_state_name: str = 'Default'\n) -&gt; Dict[str, List[Any]]\n</code></pre> <p>Get currently active filters.</p> <p>Parameters:</p> <ul> <li><code>off_set</code>: How many steps back in filter history to look</li> <li><code>context_state_name</code>: Which context state to check</li> </ul> <p>Returns:</p> <ul> <li>Dictionary of active filters</li> </ul> <p>Example:</p> <pre><code># Get current filters\ncurrent_filters = cube.get_filters()\nprint(f\"Current filters: {current_filters}\")\n</code></pre>"},{"location":"api/get_analytics_components/","title":"Hypercube Components","text":"<p>These methods let you see what's available and how everything is defined in your hypercube.</p>"},{"location":"api/get_analytics_components/#get-dimensions","title":"Get Dimensions","text":"<pre><code>get_dimensions() -&gt; List[str]\n</code></pre> <p>Returns a list of all available dimension columns across all tables.</p> <p>Example:</p> <pre><code># Get all available dimensions\nall_dimensions = cube.get_dimensions()\nprint(f\"Available dimensions: {all_dimensions}\")\n</code></pre>"},{"location":"api/get_analytics_components/#get-metrics","title":"Get Metrics","text":"<pre><code>cube.get_metrics() -&gt; Dict[str, Any]\n</code></pre> <p>Retrieve all defined metrics in the hypercube. Metrics are one of the core components of the hypercube, representing the calculated values and KPIs used for data analysis. Metrics encapsulate business logic, ensuring consistent calculations across all queries and reports.</p> <p>Returns:</p> <ul> <li>Dictionary of metrics with their details (name, expression, aggregation, and other properties)</li> </ul>"},{"location":"api/get_analytics_components/#get-queries","title":"Get Queries","text":"<pre><code>cube.get_queries() -&gt; Dict[str, Any]\n</code></pre> <p>Returns:</p> <ul> <li>Dictionary of queries with their dimensions, metrics, and display options</li> </ul>"},{"location":"api/hypercube/","title":"Hypercube API","text":"<p>The Hypercube class is the central component of Cube Alchemy, providing methods for creating, querying, and analyzing multidimensional data.</p>"},{"location":"api/hypercube/#initialization","title":"Initialization","text":"<p>The Hypercube can be initialized in two ways:</p> <pre><code># Option 1: Initialize with data\nHypercube(\n  tables: Dict[str, pd.DataFrame] = None,\n  apply_composite: bool = True,\n  validate: bool = True,\n  to_be_stored: bool = False\n)\n\n# Option 2: Initialize empty and load data later\nHypercube()\nload_data(\n  tables: Dict[str, pd.DataFrame],\n  apply_composite: bool = True,\n  validate: bool = True,\n  to_be_stored: bool = False,\n  reset_all: bool = False\n)\n</code></pre> <p>The <code>load_data()</code> method can also be used to reload or update data in an existing hypercube.</p> <p>Parameters:</p> <ul> <li><code>tables</code>: Dictionary mapping table names to pandas DataFrames</li> <li><code>apply_composite</code>: Whether to automatically create composite keys for multi-column relationships</li> <li><code>validate</code>: Whether to validate schema and build trajectory cache during initialization</li> <li><code>to_be_stored</code>: Set to True if the hypercube will be serialized/stored (skips Default context state creation)</li> <li><code>reset_all</code> (only load_data method): Whether to reset metrics and queries definitions, as well as registered functions when reloading data</li> </ul> <p>Examples:</p> <pre><code>import pandas as pd\nfrom cube_alchemy import Hypercube\n\n# Option 1: Initialize with data\ncube1 = Hypercube({\n    'Product': products_df,\n    'Customer': customers_df,\n    'Sales': sales_df\n})\n\n# Option 2: Initialize empty first, then load data\ncube2 = Hypercube()\ncube2.load_data({\n    'Product': products_df,\n    'Customer': customers_df,\n    'Sales': sales_df\n})\n\n# Reload data in an existing hypercube (e.g., when data is updated)\ncube1.load_data({\n    'Product': updated_products_df,\n    'Customer': updated_customers_df,\n    'Sales': updated_sales_df\n})\n\n# Reset metrics and queries when loading new data schema\ncube2.load_data(new_data, reset_all=True)\n</code></pre>"},{"location":"api/hypercube/#core-methods","title":"Core Methods","text":"<p>visualize_graph</p> <pre><code>visualize_graph(layout_type: str = 'spring', w: int = 12, h: int = 8, full_column_names: bool = True) -&gt; None\n</code></pre> <p>Visualize the relationships between tables as a network graph.</p> <p>Parameters:</p> <ul> <li> <p><code>layout_type</code>: Algorithm for graph layout. Options include:</p> <ul> <li><code>'spring'</code>(default)</li> <li><code>'circular'</code></li> <li><code>'shell'</code></li> <li><code>'random'</code></li> <li><code>'kamada_kawai'</code></li> <li><code>'spectral'</code></li> <li><code>'planar'</code></li> <li><code>'spiral'</code></li> </ul> </li> <li> <p><code>w</code>: Width of the plot</p> </li> <li> <p><code>h</code>: Height of the plot</p> </li> <li> <p><code>full_column_names</code>: Whether to show renamed columns with table reference (e.g., <code>column &lt;table_name&gt;</code>) or just the original column names</p> </li> </ul> <p>Example:</p> <p><pre><code># Visualize the data model relationships\ncube.visualize_graph()\n\n# Hide renamed column format for cleaner display\ncube.visualize_graph('spring', w=20, h=12, full_column_names=False)\n</code></pre> Note: If the displayed graph doesn't look so good try a couple of times or adjust the size.</p> <p>set_context_state</p> <pre><code>set_context_state(context_state_name: str) -&gt; bool\n</code></pre> <p>Create a new context state for independent filtering environments.</p> <p>Parameters:</p> <ul> <li><code>context_state_name</code>: Name for the new context state</li> </ul> <p>Returns:</p> <ul> <li>Boolean indicating success</li> </ul> <p>Example:</p> <pre><code># Create a new context state\ncube.set_context_state('Marketing Analysis')\n\n# Apply filters specific to this context\ncube.filter({'channel': ['Email', 'Social']}, context_state_name='Marketing Analysis')\n</code></pre>"},{"location":"api/metric_methods/","title":"Metric Methods","text":""},{"location":"api/metric_methods/#define-metric","title":"Define Metric","text":"<pre><code>define_metric(\n    name: Optional[str] = None,\n    expression: Optional[str] = None,\n    aggregation: Optional[Union[str, Callable[[Any], Any]]] = None,\n    metric_filters: Optional[Dict[str, Any]] = None,\n    row_condition_expression: Optional[str] = None,\n    context_state_name: str = 'Default',\n    fillna: Optional[any] = None\n)\n</code></pre> <p>Defines a metric and stores it in the cube object for later use in queries.</p> <p>Parameters:</p> <ul> <li><code>name</code>: Label for the metric (used in query results)</li> <li><code>expression</code>: Calculation formula using [column] references and @custom_functions</li> <li><code>aggregation</code>: How to combine values - pandas aggregation string ('sum', 'mean', 'count') or custom callable</li> <li><code>metric_filters</code>: Filters applied only when evaluating this specific metric</li> <li><code>metric_filters</code>: Filters applied only when evaluating this specific metric</li> <li><code>row_condition_expression</code>: Filter expression applied to rows before calculating the metric</li> <li><code>context_state_name</code>: Which context state this metric operates in</li> <li><code>fillna</code>: Value to use for replacing NaN results</li> </ul> <p>Example:</p> <pre><code># Define a revenue metric\ncube.define_metric(\n    name='Revenue',\n    expression='[qty] * [price]',\n    aggregation='sum'\n)\n\n# Sum sales only from Australia\n# Note: This differs from using metric_filters={'region': ['Australia']} in how the filtering is applied:\n# - row_condition_expression: Fetches all the rows, then applies pandas .query() with backtick syntax\n# - metric_filters: Applied at the context state level before metric calculation\n# The row_condition_expression fetches all the rows for the column which can result in different aggregation values depending on your data relationships.\ncube.define_metric(\n    name='Australia Sales',\n    expression='[sales_amount]',\n    aggregation='sum',\n    row_condition_expression='[region] == \"Australia\"'\n)\n</code></pre> <p>Syntax Rules</p> <ul> <li> <p>Column References: Columns in metric expressions must be enclosed in square brackets: <code>[qty]</code>, <code>[price]</code>, <code>[cost]</code>, etc.</p> </li> <li> <p>Aggregation Methods: The <code>aggregation</code> parameter accepts:</p> </li> <li> <p>Pandas group by strings: <code>'sum'</code>, <code>'mean'</code>, <code>'count'</code>, <code>'min'</code>, <code>'max'</code>, etc.</p> </li> <li> <p>Custom callable functions: <code>lambda x: x.quantile(0.95)</code> or any function that accepts a pandas Series</p> </li> </ul>"},{"location":"api/metric_methods/#register-function","title":"Register Function","text":"<pre><code>register_function(**kwargs)\n</code></pre> <p>Register custom functions to use in metric expressions with @function_name syntax.</p> <p>Parameters:</p> <ul> <li><code>**kwargs</code>: Keyword arguments where each key is the name to use in expressions and each value is the function</li> </ul> <p>Example:</p> <pre><code>import numpy as np\n\n# Define a custom function\ndef safe_division(numerator, denominator, default=0.0):\n    \"\"\"Safely divide two arrays, handling division by zero\"\"\"\n    result = numerator / denominator\n    return result.replace([np.inf, -np.inf], np.nan).fillna(default)\n\n# Register the function with your hypercube\ncube.register_function(safe_division=safe_division)\n\n# Use in metric definition\ncube.define_metric(\n    name='Profit Margin %',\n    expression='@safe_division([revenue] - [cost], [revenue]) * 100',\n    aggregation='mean'\n)\n</code></pre>"},{"location":"api/query_methods/","title":"Query Methods","text":""},{"location":"api/query_methods/#define-query","title":"Define Query","text":"<pre><code>define_query(\n    query_name: str,\n    dimensions: set[str] = {},\n    metrics: List[str] = [],\n    drop_null_dimensions: bool = False,\n    drop_null_metric_results: bool = False\n)\n</code></pre> <p>Defines a named query with dimensions and metrics for later execution.</p> <p>Parameters:</p> <ul> <li><code>query_name</code>: A unique name for the query</li> <li><code>dimensions</code>: Set of dimension column names to include in the query</li> <li><code>metrics</code>: List of metric names (as defined with define_metric)</li> <li><code>drop_null_dimensions</code>: Whether to exclude rows where dimension values are missing</li> <li><code>drop_null_metric_results</code>: Whether to exclude rows where metric calculations result in null</li> </ul> <p>Example:</p> <pre><code># Define metrics\ncube.define_metric(name='Revenue', expression='[qty] * [price]', aggregation='sum')\ncube.define_metric(name='Units', expression='[qty]', aggregation='sum')\n\n# Define a query using those metrics\ncube.define_query(\n    query_name=\"sales_analysis\",\n    dimensions=set(['region', 'category', 'promo_type']),\n    metrics=['Revenue', 'Units']\n)\n</code></pre>"},{"location":"api/query_methods/#execute-query","title":"Execute Query","text":"<pre><code>query(query_name: str) -&gt; pd.DataFrame\n</code></pre> <p>Executes a previously defined query by name.</p> <p>Parameters:</p> <ul> <li><code>query_name</code>: Name of a previously defined query</li> </ul> <p>Returns:</p> <ul> <li>Pandas DataFrame with the query results</li> </ul> <p>Example:</p> <pre><code># Define a query\ncube.define_query(\n    query_name=\"sales_analysis\",\n    dimensions=set(['region', 'category']),\n    metrics=['Revenue', 'Units']\n)\n\n# Execute the query\nresult = cube.query(\"sales_analysis\")\n\n# Apply a filter and run the same query again\ncube.filter({'region': ['North']})\nfiltered_result = cube.query(\"sales_analysis\")\n</code></pre>"},{"location":"api/query_methods/#dimensions-only","title":"Dimensions Only","text":"<pre><code>dimensions(\n  columns_to_fetch: List[str],\n  retrieve_keys: bool = False,\n  context_state_name: str = 'Default',\n  query_filters: Optional[Dict[str, Any]] = None\n) -&gt; pd.DataFrame\n</code></pre> <p>Fetch unique values for specified dimension columns.</p> <p>Parameters:</p> <ul> <li><code>columns_to_fetch</code>: List of dimension column names to retrieve</li> <li><code>retrieve_keys</code>: Whether to include link table keys in the result</li> <li><code>context_state_name</code>: Which context state to use</li> <li><code>query_filters</code>: Additional filters to apply just for this query</li> </ul> <p>Returns:</p> <ul> <li>Pandas DataFrame with unique combinations of the requested dimensions</li> </ul> <p>Example:</p> <pre><code># Get unique region/category combinations\nresult = cube.dimensions(['region', 'category'])\n\n# Get unique region/category combinations from a specific context state\nresult = cube.dimensions(['region', 'category'], context_state_name='State1')\n</code></pre>"},{"location":"concepts/context-state/","title":"Context State","text":"<p>You can think of it as a separate filtering environment.</p> <p>There are two main context states:</p> <ul> <li> <p>'Unfiltered': This is created at the hypercube initialization. It has all the relationships that exists accross all the tables that conform the DAG when there is no filter applied. It is a special internal use state, and is not allowed to filter on it.</p> </li> <li> <p>'Default': When initializing the hypercube on memory, we take a copy of the unfiltered state. Then by default the filters and queries will use this context state, but you can change that..</p> </li> </ul> <p>More states (?)</p> <p>You can also create more context states, as many as you want. They allow you to create multiple independent filtering contexts within the same app, so you can compare, isolate, or simulate different scenarios side by side.</p> <p>Creating new context states:</p> <pre><code># Create a new filtering environment\ncube.set_context_state('New Analysis')\n\n# Apply filters specific to this context\ncube.filter(\n    {'date': ['2024-10-01', '2024-11-01', '2024-12-01']}, \n    context_state_name='New Analysis'\n)\n\n# Define metrics using the specific context state\ncube.define_metric(\n    name='New Analysis Revenue',\n    expression='[qty] * [price]', \n    aggregation='sum',\n    context_state_name='New Analysis'  # This metric uses the New Analysis context\n)\n\n# Define regular metrics (using Default context)\ncube.define_metric(\n    name='Regular Revenue',\n    expression='[qty] * [price]', \n    aggregation='sum'\n    # No context_state_name means it uses 'Default'\n)\n\n# Define a query that will use both metrics\ncube.define_query(\n    query_name=\"revenue_comparison\",\n    dimensions={'region'},\n    metrics=['Regular Revenue', 'New Analysis Revenue']\n    # Queries don't have context_state_name parameter\n)\n\n# Execute the query - it will show revenue from both context states\ncomparison_results = cube.query(\"revenue_comparison\")\n</code></pre> <p>Bear in mind that when creating a new context state, a copy of the 'Unfiltered' state is made and stored on memory.</p> <p>Note</p> <p>In a more realistic workflow, when suporting multiple users/sessions with the same data model, you might not want to initialize and build the relationships (deploy the keys) accross the entire DAG in every session.</p> <p>One way of dealing with this is by storing the already initialized hypercube (eg. using pickle) and then retrieving it later on when a user needs it. In this case it is better if you do not store the <code>Default</code> on disk and instead you set it once the hypercube is loaded. </p> <p>Make sure if this is the case that you perform cube.set_context_state('Default') right after loading it, so the default state will be present and work.</p>"},{"location":"concepts/dimensions/","title":"Dimensions","text":"<p>Dimensions are the categorical columns from your DataFrames that you use to slice and group your data. Think of them as the \"by what\" in your analysis\u2014region, product category, time period, customer segment, and so on.</p> <p>In Cube Alchemy, any column from any table in your hypercube can serve as a dimension.</p> <p>How dimensions work:</p> <ul> <li>Available everywhere: Once your DataFrames are connected in the hypercube, dimensions from any table can be used in any query</li> <li>Auto-joining: When you query dimensions from different tables, the hypercube automatically traverses the relationships to bring them together</li> <li>Multi-hop: You can combine dimensions that are several \"hops\" apart in your data model\u2014like querying by both customer region and product category even if they're in completely separate tables</li> </ul> <p>Getting dimension values:</p> <p>You can fetch unique values for any dimension using <code>cube.query(['dimension_name'])</code>. This is useful for building filters, dropdowns in apps, or just exploring what values are available:</p> <pre><code># Get combinations of region and category\ncube.dimensions(['region', 'category'])\n\n# Or you can use the query method, but you first need to define the query without metrics\ncube.define_query(\n    query_name=\"dimension_combinations\",\n    dimensions=set(['region', 'category'])\n)\ncube.query('dimension_combinations')\n</code></pre>"},{"location":"concepts/filters/","title":"Understanding Filters","text":"<p>Filters in Cube Alchemy let you focus your analysis on specific slices of data without modifying your underlying queries.</p>"},{"location":"concepts/filters/#how-filtering-works","title":"How Filtering Works","text":"<p>When you apply a filter to a context state, all queries and metrics operate only on the filtered data until you change or remove the filter:</p> <ol> <li>Apply a filter to select specific data values</li> <li>Execute queries to analyze just the filtered data</li> <li>Modify or remove filters when you want to change focus</li> </ol> <pre><code># Define metrics first\ncube.define_metric(name='Revenue', expression='[qty] * [price]', aggregation='sum')\n\n# Now all queries only see North and West data\ncube.define_query(\n    query_name=\"sales\",\n    dimensions={'category'},\n    metrics=['Revenue']\n)\n\n# Focus on specific regions\ncube.filter({'region': ['North', 'West']})\n\ncube.query(\"sales\")\n</code></pre> <p>The beauty of Cube Alchemy filtering is that it works seamlessly across all your connected tables. When you filter by customer region, it automatically affects sales data, product data, and anything else connected through your data model relationships.</p>"},{"location":"concepts/filters/#basic-filtering-operations","title":"Basic Filtering Operations","text":""},{"location":"concepts/filters/#apply-filters","title":"Apply Filters","text":"<p>Filters are defined as dictionaries where keys are dimension names and values are lists of allowed values:</p> <pre><code># Single dimension, multiple values\ncube.filter({'region': ['North', 'West', 'South']})\n\n# Multiple dimensions at once\ncube.filter({\n    'region': ['North', 'West'], \n    'product_category': ['Electronics'],\n    'customer_segment': ['Enterprise', 'SMB']\n})\n</code></pre>"},{"location":"concepts/filters/#remove-specific-filters","title":"Remove Specific Filters","text":"<p>Remove filters from specific dimensions while keeping others intact:</p> <pre><code># Remove filter on region only (keep other filters)\ncube.remove_filter(['region'])\n\n# Remove multiple filters at once\ncube.remove_filter(['region', 'product_category'])\n</code></pre>"},{"location":"concepts/filters/#reset-all-filters","title":"Reset All Filters","text":"<p>Clear all filters to return to the full dataset:</p> <pre><code># Remove all filters (back to unfiltered data)\ncube.reset_filters(direction='all')\n</code></pre>"},{"location":"concepts/filters/#view-current-filters","title":"View Current Filters","text":"<p>Check which filters are currently active:</p> <pre><code># Get dictionary of active filters\ncurrent_filters = cube.get_filters()\nprint(current_filters)\n# Output: {'region': ['North', 'West'], 'category': ['Electronics']}\n</code></pre>"},{"location":"concepts/filters/#filter-history-and-undoredo","title":"Filter History and Undo/Redo","text":"<p>Cube Alchemy maintains your filtering history, allowing you to navigate through previous filter states:</p> <pre><code># Undo last filter operation (step backward)\ncube.reset_filters(direction='backward')\n\n# Redo previously undone filter (step forward)\ncube.reset_filters(direction='forward')\n\n# Clear all filters and history\ncube.reset_filters(direction='all')\n\n# See which dimensions currently have active filters\nfiltered_dims = cube.get_filtered_dimensions()\n</code></pre>"},{"location":"concepts/filters/#advanced-filtering-techniques","title":"Advanced Filtering Techniques","text":""},{"location":"concepts/filters/#per-metric-filters","title":"Per-Metric Filters","text":"<p>While filters apply globally to your hypercube's context state, individual metrics can have their own additional filters:</p> <pre><code># Global filter: only Electronics category\ncube.filter({'category': ['Electronics']})\n\n# Define metric with additional filter: only Premium-tier electronics\ncube.define_metric(\n    name='Premium Revenue',\n    expression='[qty] * [price]',\n    aggregation='sum',\n    metric_filters={'price_tier': ['Premium']}  # Additional filter just for this metric\n)\n</code></pre>"},{"location":"concepts/filters/#unfiltered-and-default-context-states","title":"'Unfiltered' and 'Default' Context States","text":"<p>Cube Alchemy maintains two special context states called 'Unfiltered' and 'Default'.</p> <p>'Unfiltered' always contains your full dataset in the context and cannot be updated. </p> <p>'Default' is used as default (as you might have guessed). And 'Unfiltered' can also be used on the metric context state: </p> <pre><code># Define standard revenue metric in the default (filtered) context\ncube.define_metric(\n    name='Filtered Revenue',\n    expression='[qty] * [price]',\n    aggregation='sum'\n    #, context_state_name='Default'\n)\n\n# Apply some filters to the default context\ncube.filter({'region': ['North', 'South']}) # Applies on 'Default'\n\n# Define a metric using the special Unfiltered context\ncube.define_metric(\n    name='Total Revenue',\n    expression='[qty] * [price]',\n    aggregation='sum',\n    context_state_name='Unfiltered'  # Always uses the full dataset\n)\n\n# Define a query that compares filtered and unfiltered metrics\ncube.define_query(\n    query_name=\"revenue_comparison\",\n    dimensions={'product_category'},\n    metrics=['Filtered Revenue', 'Total Revenue']\n)\n\n# The result will show revenue for North and South regions alongside\n# the total revenue across all regions for each product category\nresult = cube.query(\"revenue_comparison\")\n</code></pre> <p>For complete details on all filtering capabilities, see the Filter Methods API documentation.</p>"},{"location":"concepts/hypercube/","title":"The Hypercube","text":"<p>A hypercube is a multidimensional data structure that organizes information across multiple dimensions simultaneously. In data analysis, it extends beyond two-dimensional tables to create a unified view that connects related data across multiple attributes.</p> <p>In Cube Alchemy, the Hypercube brings multiple DataFrames together into a single, logical structure you can query consistently. Instead of manually joining tables, it dynamically connects your data.</p> <p>At a glance:</p> <ul> <li> <p>Directed Acyclic Graph (DAG)</p> <ul> <li> <p>Nodes are your DataFrames.</p> </li> <li> <p>Edges are the shared column names that connect them.</p> </li> </ul> </li> <li> <p>Queries' dimensions and metrics can traverse these connections (multi-hop) to combine the pieces your analysis needs. You define the metrics and queries once, and they work consistently across your analysis using a context state managed with filters.</p> </li> </ul> <p>Note</p> <p>To be able to multi-hop through the related tables, we need to avoid cyclic relationships (also called circular references), as this breaks the logic of data traversal and aggregation. So you need to make sure your model is a directed acyclic graph (DAG).</p>"},{"location":"concepts/metrics/","title":"Understanding Metrics","text":"<p>A metric is a calculated measure that aggregates data in some meaningful way. Think revenue, profit margin, average order size, customer count\u2014basically any aggregated value that helps you analyze your data.</p> <p>In Cube Alchemy, metrics are defined once and stored within the cube object for later use:</p> <ol> <li>You define a metric using <code>cube.define_metric()</code> providing a name, expression, and aggregation method</li> <li>The metric is stored in the cube object</li> <li>Later, you reference metrics by name when defining queries</li> </ol>"},{"location":"concepts/metrics/#building-a-metric","title":"Building a Metric","text":"<p>Every metric needs three essential components:</p> <ol> <li>Name: A clear, descriptive label for the metric (e.g., 'Revenue', 'Customer Count')</li> <li>Expression: The calculation formula, using column references inside square brackets (e.g., <code>[qty] * [price]</code>)</li> <li>Aggregation: How to combine values\u2014standard methods like <code>sum</code>, <code>mean</code>, <code>count</code>, or custom functions</li> </ol> <pre><code># Step 1: Define your metrics\ncube.define_metric(\n    name='Revenue',\n    expression='[qty] * [price]',\n    aggregation='sum'\n)\n\ncube.define_metric(\n    name='Average Order Value', \n    expression='[price]',\n    aggregation='mean'\n)\n\ncube.define_metric(\n    name='Number of Orders',\n    expression='[order_id]',\n    aggregation='count'\n)\n\n# Step 2: Define a query that uses these metrics\ncube.define_query(\n    query_name=\"sales_performance\",\n    dimensions=set(['region', 'product_category']),\n    metrics=['Revenue', 'Average Order Value', 'Number of Orders']\n)\n\n# Step 3: Execute the query by referencing its name\nresult = cube.query(\"sales_performance\")\n\n# The metrics are calculated and returned as columns in the result DataFrame\n</code></pre>"},{"location":"concepts/metrics/#syntax-rules","title":"Syntax Rules","text":"<ul> <li> <p>Column References: Columns in metric expressions must be enclosed in square brackets: <code>[qty]</code>, <code>[price]</code>, <code>[cost]</code>, etc.</p> </li> <li> <p>Aggregation Methods: The <code>aggregation</code> parameter accepts:</p> </li> <li> <p>Pandas group by strings: <code>'sum'</code>, <code>'mean'</code>, <code>'count'</code>, <code>'min'</code>, <code>'max'</code>, etc.</p> </li> <li> <p>Custom callable functions: <code>lambda x: x.quantile(0.95)</code> or any function that accepts a pandas Series</p> </li> </ul>"},{"location":"concepts/metrics/#advanced-features","title":"Advanced Features","text":"<p>For more sophisticated analysis, metrics support several powerful options:</p> <ul> <li>Different context states: Calculate metrics in different filtering environments</li> <li>Metric filters: Apply specific filters only for a particular metric</li> <li>Row conditions: Pre-filter rows before calculating the metric</li> <li>Custom functions: Use your own Python functions for complex logic</li> </ul> <p>Each of these options allows you to create highly specialized metrics that can answer specific business questions within the same analytical framework.</p> <pre><code># Only count high-value orders\ncube.define_metric(\n    name='High Value Orders',\n    expression='[order_id]',\n    aggregation='count',\n    row_condition_expression='[price] &gt; 100'\n)\n\n# Revenue only from specific regions (metric-level filter)\ncube.define_metric(\n    name='Regional Revenue',\n    expression='[qty] * [price]',\n    aggregation='sum',\n    metric_filters={'region': ['North', 'West']}\n)\n\n# Create a new Context State\ncube.set_context_state('My New Context')\n\n# Apply different filters to it\ncube.filter(\n    {'date': ['2024-10-01', '2024-11-01', '2024-12-01']},\n    context_state_name='My New Context'\n)\n\n# Define a metric using the new context\ncube.define_metric(\n    name='High Value Orders',\n    expression='[order_id]',\n    aggregation='count',\n    context_state_name='My New Context'\n)\n\n# Define a query with these metrics\ncube.define_query(\n    query_name=\"advanced_analysis\",\n    dimensions=set(my_query_dimensions),\n    metrics=['High Value Orders', 'Regional Revenue', 'High Value Orders']\n)\n\n# Execute the query\nresult = cube.query(\"advanced_analysis\")\n</code></pre>"},{"location":"concepts/metrics/#custom-functions","title":"Custom Functions","text":"<p>When your analysis requires logic that goes beyond basic arithmetic, you can register and use custom Python functions:</p> <ol> <li>Define a Python function that performs your specialized calculation</li> <li>Register the function with your cube using <code>cube.register_function()</code></li> <li>Reference the function in your metric expressions using the <code>@function_name</code> syntax</li> </ol> <p>This powerful feature allows you to implement virtually any calculation logic while keeping your metric definitions clean and readable.</p> <pre><code>import numpy as np\n\n# Define and register a safe division function\ndef safe_division(numerator, denominator, default=0.0):\n    \"\"\"Safely divide two arrays, handling division by zero\"\"\"\n    result = numerator / denominator\n    return result.replace([np.inf, -np.inf], np.nan).fillna(default)\n\n# Register the function with your hypercube\ncube.register_function(safe_division=safe_division)\n\n# Use it in a metric definition\ncube.define_metric(\n    name='Profit Margin %',\n    expression='@safe_division([revenue] - [cost], [revenue]) * 100',\n    aggregation='mean'\n)\n\n# Another example: categorizing data\ndef categorize_revenue(revenue_values):\n    \"\"\"Categorize revenue into tiers\"\"\"\n    conditions = [\n        revenue_values &lt; 1000,\n        (revenue_values &gt;= 1000) &amp; (revenue_values &lt; 5000),\n        revenue_values &gt;= 5000\n    ]\n    choices = ['Low', 'Medium', 'High']\n    return np.select(conditions, choices, default='Unknown')\n\ncube.register_function(categorize_revenue=categorize_revenue)\n\n# Use for conditional logic - count how many sales fall into each tier\ncube.define_metric(\n    name='Revenue Tier Count',\n    expression='@categorize_revenue([qty] * [price])',\n    aggregation=lambda x: len(x)\n)\n\n# Or get the most common revenue tier\ncube.define_metric(\n    name='Most Common Revenue Tier',\n    expression='@categorize_revenue([qty] * [price])',\n    aggregation=lambda x: x.value_counts().index[0]\n)\n</code></pre> <p>Note on Function Handling</p> <p>Metric aggregation allows you to pass custom functions directly while expression functions need to be registered on the hypercube first and referenced with <code>@function_name</code>. This difference exists due to their roles in the processing pipeline:</p> <ul> <li>Expression functions operate inside within dataframe rows before aggregation</li> <li>Aggregation functions work outside on the grouped data</li> </ul>"},{"location":"concepts/queries/","title":"Understanding Queries","text":"<p>Queries in Cube Alchemy bring together metrics and dimensions to answer specific business questions.</p> <p>A query consists of three key components:</p> <ul> <li> <p>Query name: A unique identifier for referencing the query</p> </li> <li> <p>Dimensions: Columns to group by (the \"by what\" in your analysis)</p> </li> <li> <p>Metrics: Measures to calculate (the \"what\" in your analysis)</p> </li> </ul> <pre><code># Define metrics\ncube.define_metric(name='Revenue', expression='[qty] * [price]', aggregation='sum')\ncube.define_metric(name='Order Count', expression='[order_id]', aggregation='count')\n\n# Define a query by region and product category\ncube.define_query(\n    query_name=\"regional_sales\",\n    dimensions={'region', 'category'},  # Using direct set literal\n    metrics=['Revenue', 'Order Count']\n)\n\n# Execute the query\nresult = cube.query(\"regional_sales\")\n</code></pre>"},{"location":"concepts/queries/#how-query-execution-works","title":"How Query Execution Works","text":"<p>When you run a query, Cube Alchemy efficiently processes your data in four steps:</p> <ol> <li>Group metrics by context: Metrics sharing the same context state and custom metric filters are calculated together</li> <li>Fetch required data: All necessary dimension and metric columns are retrieved automatically, traversing table relationships and getting the required indexes</li> <li>Apply aggregations: Each metric's aggregation is applied to the corresponding dimensions</li> <li>Merge results: The individual metric calculations are combined based on your specified dimensions</li> </ol>"},{"location":"concepts/queries/#query-types","title":"Query Types","text":"<p>Queries must contain either dimensions, metrics, or both (a query cannot lack both).</p>"},{"location":"concepts/queries/#dimension-only-queries","title":"Dimension-Only Queries","text":"<p>When you only need to see what unique dimension combinations exist in your data:</p> <pre><code># Define a query with only dimensions\ncube.define_query(\n    query_name=\"dimension_combinations\",\n    dimensions={'region', 'category'}\n)\n\n# Get all unique region/category combinations\ncombinations = cube.query(\"dimension_combinations\")\n</code></pre>"},{"location":"concepts/queries/#metric-only-queries","title":"Metric-Only Queries","text":"<p>When you need to calculate global aggregates across your entire dataset:</p> <pre><code># Define metrics\ncube.define_metric(name='Total Revenue', expression='[qty] * [price]', aggregation='sum')\ncube.define_metric(name='Total Orders', expression='[order_id]', aggregation='count')\n\n# Define a query with no dimensions\ncube.define_query(\n    query_name=\"global_totals\",\n    metrics=['Total Revenue', 'Total Orders']\n)\n\n# Execute the query\nglobal_results = cube.query(\"global_totals\")\n</code></pre>"},{"location":"concepts/queries/#query-options","title":"Query Options","text":"<p>Fine-tune your query results with these options:</p> <ul> <li><code>drop_null_dimensions=True</code>: Remove rows with missing dimension values</li> <li><code>drop_null_metric_results=True</code>: Remove rows with null metric results</li> </ul> <pre><code>cube.define_query(\n    query_name=\"clean_sales_data\",\n    dimensions={'region', 'category'},\n    metrics=['Revenue', 'Orders'],\n    drop_null_dimensions=True,\n    drop_null_metric_results=True\n)\n</code></pre>"},{"location":"concepts/queries/#working-with-filters","title":"Working with Filters","text":"<p>Queries automatically respect all active filters on your hypercube, allowing you to:</p> <ol> <li>Define a query once</li> <li>Apply different filters</li> <li>Execute the same query to see different filtered views of your data</li> </ol> <pre><code># Define your query\ncube.define_query(\n    query_name=\"product_sales\",\n    dimensions={'region', 'product_category'},\n    metrics=['Revenue', 'Order Count']\n)\n\n# Get unfiltered results\nunfiltered_results = cube.query(\"product_sales\")\n\n# Apply filters\ncube.filter({'product_type': ['Electronics', 'Home']})\n\n# Get filtered results using the same query\nfiltered_results = cube.query(\"product_sales\")\n</code></pre>"},{"location":"concepts/relationships/","title":"Relationships in Cube Alchemy","text":"<p>Cube Alchemy uses implicit relationships, meaning DataFrames automatically connect to each other through shared column names. This creates a unified data model without requiring you to write explicit joins.</p> <p>These relationships enable you to:</p> <ul> <li> <p>Traverse the entire data model seamlessly</p> </li> <li> <p>Query across multiple tables without complex join logic</p> </li> <li> <p>Select dimensions from any table in your schema</p> </li> <li> <p>Create metrics using columns from any connected table</p> </li> </ul> <p>Cube Alchemy handles all the necessary data operations under the hood, so you can use more of your time to focus on analysis.</p>"},{"location":"concepts/relationships/#single-path","title":"Single Path","text":"<p>Cube Alchemy ensures there is exactly one bidirectional path between any two tables in your data model. This creates a clear, unambiguous way to traverse from one table to another.</p>"},{"location":"concepts/relationships/#composite-key","title":"Composite Key","text":"<p>When tables share multiple columns, Cube Alchemy automatically creates composite keys to properly connect them:</p> <ol> <li>Detection: The system identifies sets of shared columns between tables</li> <li>Composite Key Creation: A single, efficient key is generated from these shared columns</li> <li>Composite Tables: New tables are created to store only the shared columns along with the generated keys</li> <li>Column Renaming: The original shared columns in source tables are renamed with a format of <code>column_name &lt;table_name&gt;</code></li> <li>Key Addition: The newly created composite keys are added to the original tables</li> </ol> <p>This process consolidates complex relationships into simple, efficient connections while preserving all the original data.</p>"},{"location":"concepts/relationships/#cardinality","title":"Cardinality","text":"<p>Cube Alchemy takes a flexible approach:</p> <ul> <li> <p>It does not enforce specific cardinality constraints like one-to-many or many-to-one; many-to-many is the default relationship.</p> </li> <li> <p>You should understand your data's natural cardinality to avoid unexpected results in your aggregations (e.g., due to row duplication).</p> </li> </ul>"},{"location":"concepts/relationships/#visualization","title":"Visualization","text":"<p>When setting up your hypercube, it's a good idea to inspect the relationship graph to confirm how tables connect and where composite keys have been introduced.  <pre><code># Default view shows renamed columns (column_name &lt;table_name&gt;)\ncube.visualize_graph()\n\n# For cleaner display without table name suffixes\ncube.visualize_graph(full_column_names=False)\n</code></pre> This visualization helps you understand the automatic transformations that Cube Alchemy has applied.</p> <p>Note: If the displayed graph doesn't look so good try a couple of times or adjust the size.</p>"},{"location":"concepts/workflow/","title":"Workflow","text":"<pre><code>flowchart LR\n  A[\"Load DataFrames\"] --&gt; B[\"Build Hypercube\"]\n  B --&gt; C[\"Define Metrics\"]\n  C --&gt; D[\"Define Queries\"]\n  D --&gt; E[\"Execute Queries\"]\n  E --&gt; F[\"Update Context State (Apply or Remove Filters)\"]\n  F --&gt; E</code></pre> <p>Cube Alchemy's workflow is intuitive and powerful: load your data, build a unified hypercube structure, define your metrics, and create reusable queries. The stateful architecture allows you to execute queries and apply filters in an iterative process, maintaining context throughout your analysis journey.</p>"}]}